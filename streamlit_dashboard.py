"""Interactive Streamlit dashboard for Amazon furniture review insights.

This app introduces a narrative-driven UI on top of the artifacts generated by the
notebook workflow. Heavy preprocessing stays outside Streamlit; the app reads the
exported TSV/JSON/GZIP files with caching so stakeholders can explore stories quickly.
"""

from __future__ import annotations

import gzip
import json
from pathlib import Path
from typing import Any, Dict, List, Sequence

import pandas as pd
import plotly.express as px
import streamlit as st

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
DATASET_PATH = BASE_DIR / "amazon_reviews_us_Furniture_v1_00_filtered.tsv"
CLEAN_INSIGHTS_PATH = BASE_DIR / "review_insights_checkpoint_cleaned.json.gz"
CLUSTER_INSIGHTS_PATH = BASE_DIR / "review_clusters_full.json.gz"
CHARTS_DIR = BASE_DIR / "furniture_insight_charts"


# ---------------------------------------------------------------------------
# Data loading helpers
# ---------------------------------------------------------------------------
def _safe_path_readable(path: Path) -> bool:
    return path.exists() and path.is_file()


@st.cache_data(show_spinner=False)
def load_reviews_dataframe(path: Path) -> pd.DataFrame:
    """Load the filtered TSV of Amazon reviews."""
    if not _safe_path_readable(path):
        return pd.DataFrame()

    df = pd.read_csv(
        path,
        sep="\t",
        parse_dates=["review_date"],
        dtype={
            "marketplace": "category",
            "product_category": "category",
            "vine": "category",
            "verified_purchase": "category",
        },
    )
    return df


@st.cache_data(show_spinner=False)
def load_clean_insights(path: Path) -> pd.DataFrame:
    """Load the cleaned insights JSON produced by the notebook pipeline."""
    if not _safe_path_readable(path):
        return pd.DataFrame()

    with gzip.open(path, "rt", encoding="utf-8") as f:
        payload: List[Dict[str, Any]] = json.load(f)

    df = pd.json_normalize(payload)
    rename_map = {
        "review_metadata.review_id": "review_id",
        "review_metadata.star_rating": "star_rating",
        "review_metadata.product_title": "product_title",
        "review_metadata.review_body": "review_body",
    }
    existing_map = {k: v for k, v in rename_map.items() if k in df.columns}
    if existing_map:
        df.rename(columns=existing_map, inplace=True)
    return df


@st.cache_data(show_spinner=False)
def load_cluster_insights(path: Path) -> pd.DataFrame:
    """Load clustering results with t-SNE coordinates."""
    if not _safe_path_readable(path):
        return pd.DataFrame()

    with gzip.open(path, "rt", encoding="utf-8") as f:
        payload: List[Dict[str, Any]] = json.load(f)

    df = pd.DataFrame(payload)
    if "star_rating" in df.columns:
        df["star_rating"] = pd.to_numeric(df["star_rating"], errors="coerce").astype("Int64")
    list_like_columns = [
        "pain_points_clean",
        "positive_aspects_clean",
        "main_themes_clean",
        "purchase_factors_clean",
        "pain_points",
        "positive_aspects",
        "main_themes",
        "purchase_decision_factors",
    ]
    for column in list_like_columns:
        if column in df.columns:
            df[column] = df[column].apply(
                lambda value: value if isinstance(value, list) else ([] if pd.isna(value) else [value])
            )
    return df


# ---------------------------------------------------------------------------
# Visualization helpers
# ---------------------------------------------------------------------------
def compute_term_counts(df: pd.DataFrame, column: str, top_n: int) -> pd.DataFrame:
    """Explode list-valued columns and aggregate counts."""
    if df.empty or column not in df.columns:
        return pd.DataFrame(columns=["name", "count"])

    exploded = df.explode(column)
    if exploded.empty:
        return pd.DataFrame(columns=["name", "count"])

    series = (
        exploded[column]
        .dropna()
        .astype(str)
        .str.strip()
        .replace("", pd.NA)
        .dropna()
    )
    counts = (
        series.value_counts()
        .head(top_n)
        .rename_axis("name")
        .reset_index(name="count")
    )
    return counts


def render_dynamic_terms(title: str | None, df: pd.DataFrame, column: str, top_n: int) -> None:
    counts = compute_term_counts(df, column, top_n)
    if counts.empty:
        st.info("No records match the current filters for this section.")
        return

    fig = px.bar(
        counts,
        x="name",
        y="count",
        text_auto=".0f",
        title=title,
    )
    fig.update_traces(marker_color="#2F4F4F", textposition="outside")
    top_margin = 90 if title else 40
    layout_kwargs = dict(
        xaxis_title="",
        yaxis_title="Mentions",
        margin=dict(l=20, r=20, t=top_margin, b=60),
    )
    if title:
        layout_kwargs["title"] = dict(
            text=title,
            x=0.5,
            y=0.98,
            xanchor="center",
            yanchor="top",
            font=dict(size=16, weight="bold"),
        )
    fig.update_layout(**layout_kwargs)
    st.plotly_chart(fig, width="stretch")
    with st.expander("View table"):
        st.dataframe(counts, hide_index=True, width="stretch")


def render_chart_gallery() -> None:
    if not CHARTS_DIR.exists():
        st.info("No exported charts detected yet.")
        return

    chart_files = sorted(CHARTS_DIR.glob("*.png"))
    if not chart_files:
        st.info("PNG charts not found in the expected directory.")
        return

    st.markdown("### Visual Gallery")
    cols = st.columns(2)
    for idx, chart_path in enumerate(chart_files):
        col = cols[idx % 2]
        with col:
            st.image(chart_path.as_posix(), caption=chart_path.name, width="stretch")


def story_image(filename: str, caption: str, narrative: str | None = None) -> None:
    path = CHARTS_DIR / filename
    if path.exists():
        st.image(path.as_posix(), caption=caption, width="stretch")
        if narrative:
            st.markdown(narrative)


def section_header(title: str, subtitle: str | None = None) -> None:
    st.markdown(f"## {title}")
    if subtitle:
        st.caption(subtitle)


@st.cache_data(show_spinner=False)
def load_latest_summary_markdown() -> str:
    files = sorted(BASE_DIR.glob("executive_summary_*.md"))
    if not files:
        return ""
    return files[-1].read_text(encoding="utf-8")


@st.cache_data(show_spinner=False)
def load_comparison_markdown() -> str:
    path = BASE_DIR / "top_vs_bottom_comparison.md"
    if not path.exists():
        return ""
    return path.read_text(encoding="utf-8")


# ---------------------------------------------------------------------------
# Filtering helpers
# ---------------------------------------------------------------------------
def apply_filters_to_insights(
    df: pd.DataFrame,
    date_range: Sequence[pd.Timestamp] | None,
    ratings: Sequence[int] | None,
    verified_choice: str,
    vine_choice: str,
    keyword: str,
) -> pd.DataFrame:
    filtered = df.copy()

    if filtered.empty:
        return filtered

    if date_range and "review_date" in filtered.columns:
        start, end = date_range
        filtered = filtered[
            filtered["review_date"].between(pd.to_datetime(start), pd.to_datetime(end))
        ]

    if ratings and "star_rating" in filtered.columns:
        filtered = filtered[filtered["star_rating"].isin(ratings)]

    if "verified_purchase" in filtered.columns and verified_choice != "All":
        target = "Y" if verified_choice == "Verified only" else "N"
        filtered = filtered[filtered["verified_purchase"] == target]

    if "vine" in filtered.columns and vine_choice != "All":
        target = "Y" if vine_choice == "Vine reviewers" else "N"
        filtered = filtered[filtered["vine"] == target]

    if keyword:
        keyword = keyword.lower()
        filtered = filtered[
            filtered["review_body"].fillna("").str.lower().str.contains(keyword)
            | filtered["product_title"].fillna("").str.lower().str.contains(keyword)
        ]

    return filtered


def apply_filters_to_reviews(
    df: pd.DataFrame,
    date_range: Sequence[pd.Timestamp] | None,
    ratings: Sequence[int] | None,
    verified_choice: str,
    vine_choice: str,
    keyword: str,
) -> pd.DataFrame:
    filtered = df.copy()

    if filtered.empty:
        return filtered

    if date_range:
        start, end = date_range
        filtered = filtered[
            filtered["review_date"].between(pd.to_datetime(start), pd.to_datetime(end))
        ]

    if ratings:
        filtered = filtered[filtered["star_rating"].isin(ratings)]

    if verified_choice != "All":
        target = "Y" if verified_choice == "Verified only" else "N"
        filtered = filtered[filtered["verified_purchase"] == target]

    if vine_choice != "All":
        target = "Y" if vine_choice == "Vine reviewers" else "N"
        filtered = filtered[filtered["vine"] == target]

    if keyword:
        keyword = keyword.lower()
        filtered = filtered[
            filtered["review_body"].fillna("").str.lower().str.contains(keyword)
            | filtered["product_title"].fillna("").str.lower().str.contains(keyword)
        ]

    return filtered


# ---------------------------------------------------------------------------
# Streamlit layout
# ---------------------------------------------------------------------------
st.set_page_config(
    page_title="Amazon Furniture Review Insights",
    layout="wide",
    page_icon="üõãÔ∏è",
)


st.title("Amazon Furniture Review Insights Dashboard")
st.markdown(
    """
This dashboard surfaces structured insights extracted from **87k+ Amazon furniture
reviews**. Use the filters on the left to focus on specific cohorts and scan the
top customer sentiments, pain points, and decision drivers that inform market
expansion planning.
"""
)


# Sidebar configuration ------------------------------------------------------
st.sidebar.header("Story Filters")
top_n = st.sidebar.slider("Top N terms to highlight", min_value=5, max_value=30, value=15, step=5)
keyword_filter = st.sidebar.text_input(
    "Keyword filter",
    value="",
    placeholder="Search product names or review text...",
)

# Load datasets --------------------------------------------------------------
reviews_df = load_reviews_dataframe(DATASET_PATH)
clean_insights_df = load_clean_insights(CLEAN_INSIGHTS_PATH)
cluster_insights_df = load_cluster_insights(CLUSTER_INSIGHTS_PATH)

if not clean_insights_df.empty:
    if "star_rating" in clean_insights_df.columns:
        clean_insights_df["star_rating"] = pd.to_numeric(
            clean_insights_df["star_rating"], errors="coerce"
        ).astype("Int64")

    list_like_columns = [
        "pain_points_clean",
        "positive_aspects_clean",
        "main_themes_clean",
        "purchase_factors_clean",
        "pain_points",
        "positive_aspects",
        "main_themes",
        "purchase_decision_factors",
    ]
    for column in list_like_columns:
        if column in clean_insights_df.columns:
            clean_insights_df[column] = clean_insights_df[column].apply(
                lambda value: value if isinstance(value, list) else ([] if pd.isna(value) else [value])
            )

    if not reviews_df.empty:
        merge_cols = [
            col
            for col in ["review_id", "review_date", "verified_purchase", "vine", "product_category"]
            if col in reviews_df.columns
        ]
        meta_df = reviews_df[merge_cols].copy()
        if "review_date" in meta_df.columns:
            meta_df["review_date"] = pd.to_datetime(meta_df["review_date"])
        clean_insights_df = clean_insights_df.merge(meta_df, on="review_id", how="left")

    if "review_date" in clean_insights_df.columns:
        clean_insights_df["review_date"] = pd.to_datetime(clean_insights_df["review_date"])

pain_col = (
    "pain_points_clean"
    if not clean_insights_df.empty and "pain_points_clean" in clean_insights_df.columns
    else "pain_points"
)
pos_col = (
    "positive_aspects_clean"
    if not clean_insights_df.empty and "positive_aspects_clean" in clean_insights_df.columns
    else "positive_aspects"
)
theme_col = (
    "main_themes_clean"
    if not clean_insights_df.empty and "main_themes_clean" in clean_insights_df.columns
    else "main_themes"
)
purchase_col = (
    "purchase_factors_clean"
    if not clean_insights_df.empty and "purchase_factors_clean" in clean_insights_df.columns
    else "purchase_decision_factors"
)

# Sidebar filters that depend on data ----------------------------------------
if not clean_insights_df.empty:
    rating_options = sorted(
        clean_insights_df["star_rating"]
        .dropna()
        .astype(int)
        .unique()
        .tolist()
    )
else:
    rating_options = (
        sorted(reviews_df["star_rating"].dropna().astype(int).unique().tolist())
        if not reviews_df.empty
        else []
    )

default_ratings = rating_options or [1, 2, 3, 4, 5]
selected_ratings = st.sidebar.multiselect(
    "Star ratings",
    options=default_ratings,
    default=default_ratings,
)
if not selected_ratings:
    selected_ratings = default_ratings

if not reviews_df.empty:
    min_date = reviews_df["review_date"].min().date()
    max_date = reviews_df["review_date"].max().date()
    date_selection = st.sidebar.date_input(
        "Review date range",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
    )
    if isinstance(date_selection, tuple) and len(date_selection) == 2:
        selected_date_range = date_selection
    else:
        selected_date_range = (min_date, max_date)
else:
    selected_date_range = None

verified_choice = st.sidebar.selectbox(
    "Purchase status",
    options=["All", "Verified only", "Non-verified"],
)

vine_choice = st.sidebar.selectbox(
    "Vine participation",
    options=["All", "Vine reviewers", "Non-vine"],
)

# Apply filters --------------------------------------------------------------
filtered_clean_df = (
    apply_filters_to_insights(
        clean_insights_df,
        selected_date_range,
        selected_ratings,
        verified_choice,
        vine_choice,
        keyword_filter,
    )
    if not clean_insights_df.empty
    else pd.DataFrame()
)

filtered_reviews_df = (
    apply_filters_to_reviews(
        reviews_df,
        selected_date_range,
        selected_ratings,
        verified_choice,
        vine_choice,
        keyword_filter,
    )
    if not reviews_df.empty
    else pd.DataFrame()
)

filtered_cluster_df = (
    apply_filters_to_insights(
        cluster_insights_df,
        selected_date_range,
        selected_ratings,
        verified_choice,
        vine_choice,
        keyword_filter,
    )
    if not cluster_insights_df.empty
    else pd.DataFrame()
)

# KPI section ----------------------------------------------------------------
section_header("At a Glance")
col1, col2, col3 = st.columns(3)
with col1:
    total_reviews = len(clean_insights_df) if not clean_insights_df.empty else len(reviews_df)
    st.metric("Reviews in View", f"{len(filtered_clean_df):,}" if not filtered_clean_df.empty else "0")
with col2:
    st.metric("Total Reviews Available", f"{total_reviews:,}" if total_reviews else "‚Äî")
with col3:
    avg_rating = (
        filtered_reviews_df["star_rating"].mean()
        if not filtered_reviews_df.empty and "star_rating" in filtered_reviews_df.columns
        else None
    )
    st.metric(
        "Average Star Rating (selection)",
        f"{avg_rating:.2f}" if avg_rating else "‚Äî",
    )

# Cached narratives -------------------------------------------------------
summary_markdown = load_latest_summary_markdown()
comparison_markdown = load_comparison_markdown()

# Story tabs --------------------------------------------------------------
overview_tab, eda_tab, sentiment_tab, clusters_tab, temporal_tab, comparison_tab = st.tabs(
    [
        "Executive Overview",
        "Exploratory Analysis",
        "Pain & Positives by Rating",
        "K-Means Clusters",
        "Temporal Trends",
        "Comparative Analysis",
    ]
)

with overview_tab:
    section_header("Executive Overview", "Spot macro trends for the current filter slice.")
    st.markdown(
        "Use the filters on the left to change who we are listening to. "
        "Scan the live metrics above, then dive into the tabs for deeper explorations."
    )
    if summary_markdown:
        with st.expander("Executive Summary", expanded=False):
            st.markdown(summary_markdown)

with eda_tab:
    section_header("Exploratory Analysis", "High-level visuals from the notebook plus interactive cuts.")
    if filtered_reviews_df.empty:
        st.info("Load the TSV dataset locally to explore distributions and helpfulness metrics.")
    else:
        eda_cols = st.columns(2)
        rating_counts = (
            filtered_reviews_df["star_rating"]
            .value_counts()
            .sort_index()
            .rename_axis("star_rating")
            .reset_index(name="review_count")
        )
        with eda_cols[0]:
            st.subheader("Rating distribution (selection)")
            if rating_counts.empty:
                st.info("No ratings available for the current filters.")
            else:
                rating_fig = px.bar(
                    rating_counts,
                    x="star_rating",
                    y="review_count",
                    text_auto=True,
                    labels={"star_rating": "Star rating", "review_count": "Reviews"},
                )
                rating_fig.update_layout(margin=dict(l=20, r=20, t=40, b=40))
                st.plotly_chart(rating_fig, width="stretch")
        with eda_cols[1]:
            st.subheader("Average helpful votes by rating")
            if "helpful_votes" in filtered_reviews_df.columns:
                helpful_df = (
                    filtered_reviews_df.groupby("star_rating", dropna=True)["helpful_votes"]
                    .mean()
                    .rename("avg_helpful_votes")
                    .reset_index()
                    .sort_values("star_rating")
                )
                if helpful_df.empty:
                    st.info("Helpful vote data not available for this slice.")
                else:
                    helpful_fig = px.bar(
                        helpful_df,
                        x="star_rating",
                        y="avg_helpful_votes",
                        labels={"star_rating": "Star rating", "avg_helpful_votes": "Avg helpful votes"},
                    )
                    helpful_fig.update_layout(margin=dict(l=20, r=20, t=40, b=40))
                    st.plotly_chart(helpful_fig, width="stretch")
            else:
                st.info("Helpful vote data not present in the loaded dataset.")

    st.markdown("### Notebook snapshots")
    story_image(
        "rating_distribution_for_furniture_reviews.png",
        "Rating distribution (all reviews)",
        "Use this baseline when you filter to specific cohorts.",
    )
    story_image(
        "review_volume_over_time.png",
        "Review volume over time (all reviews)",
        "Compare with deselected cohorts in the temporal tab.",
    )
    story_image(
        "sentiment_trend_avg.png",
        "Average sentiment trend (all reviews)",
        "Control chart for the temporal analysis tab.",
    )

with sentiment_tab:
    section_header("Pain & Positives by Rating", "Contrast the strongest detractors and delights per star level.")
    if filtered_clean_df.empty or "star_rating" not in filtered_clean_df.columns:
        st.info("Enable the cleaned insight records to explore pain points and positives by rating.")
    else:
        rating_values = sorted(filtered_clean_df["star_rating"].dropna().unique())
        for rating in rating_values:
            subset = filtered_clean_df[filtered_clean_df["star_rating"] == rating]
            if subset.empty:
                continue
            with st.expander(f"{rating}-Star Reviews ({len(subset):,})", expanded=rating in {1, 5}):
                render_dynamic_terms("Pain Points", subset, pain_col, top_n)
                render_dynamic_terms("Positive Aspects", subset, pos_col, top_n)
                render_dynamic_terms("Themes", subset, theme_col, top_n)

    st.markdown("### Notebook snapshots")
    story_image(
        "pain_points.png",
        "Top-20 pain points (all reviews)",
        "Cross-check this baseline to see where your selected cohort over-indexes.",
    )
    story_image(
        "positive_aspects.png",
        "Top positive drivers (all reviews)",
        "Identify the universal delights before drilling into your filtered cohort.",
    )
    story_image(
        "top20_overview.png",
        "Positive vs negative share across the first 20 features",
        "Helpful for spotting balanced value propositions that resonate across the journey.",
    )
    story_image(
        "purchase_decision_factors.png",
        "Purchase decision factors",
        "Great companion for messaging and go-to-market planning.",
    )

with clusters_tab:
    section_header("K-Means Clusters", "Explore persona clusters with interactive t-SNE.")
    if filtered_cluster_df.empty or {"tsne_x", "tsne_y", "cluster_id"}.difference(filtered_cluster_df.columns):
        st.info(
            "Cluster insights not available for the current configuration. "
            "Ensure `review_clusters_full.json.gz` is present and the filters are not too restrictive."
        )
    else:
        cluster_options = sorted(filtered_cluster_df["cluster_id"].dropna().unique())
        selected_clusters = st.multiselect(
            "Select clusters to highlight",
            options=cluster_options,
            default=cluster_options,
        )
        cluster_subset = filtered_cluster_df[
            filtered_cluster_df["cluster_id"].isin(selected_clusters)
        ].copy()
        if cluster_subset.empty:
            st.info("No data available for the selected clusters.")
        else:
            cluster_subset["cluster_label"] = cluster_subset["cluster_id"].astype(str)
            cluster_subset["review_snippet"] = cluster_subset["review_body"].str.slice(0, 160)

            scatter_fig = px.scatter(
                cluster_subset,
                x="tsne_x",
                y="tsne_y",
                color="cluster_label",
                hover_name="product_title",
                hover_data={
                    "cluster_label": True,
                    "star_rating": True,
                    "review_snippet": True,
                    "tsne_x": False,
                    "tsne_y": False,
                },
                labels={"cluster_label": "Cluster"},
            )
            scatter_fig.update_layout(margin=dict(l=20, r=20, t=40, b=40))
            st.plotly_chart(scatter_fig, width="stretch")

            st.markdown("### Cluster drill-down")
            cluster_sample_size = st.slider(
                "Sample reviews per cluster",
                min_value=3,
                max_value=25,
                value=10,
                step=1,
                key="cluster_sample_size",
            )
            for cluster_id in selected_clusters:
                cluster_block = cluster_subset[cluster_subset["cluster_id"] == cluster_id]
                if cluster_block.empty:
                    continue
                with st.expander(f"Cluster {cluster_id} ({len(cluster_block):,} reviews)", expanded=False):
                    render_dynamic_terms("Pain Points", cluster_block, pain_col, top_n)
                    render_dynamic_terms("Positive Aspects", cluster_block, pos_col, top_n)
                    render_dynamic_terms("Themes", cluster_block, theme_col, top_n)

                    sample_reviews = cluster_block.sample(
                        min(len(cluster_block), cluster_sample_size),
                        random_state=42,
                    )
                    for _, row in sample_reviews.iterrows():
                        with st.expander(f"{row.get('product_title', 'Review')} ‚Ä¢ {row.get('star_rating', 'N/A')}‚≠ê", expanded=False):
                            st.write(f"**Pain Points:** {', '.join(row.get(pain_col, []))}")
                            st.write(f"**Positive Aspects:** {', '.join(row.get(pos_col, []))}")
                            st.write(f"**Themes:** {', '.join(row.get(theme_col, []))}")
                            st.write("---")
                            st.write(row.get("review_body", "No review text available."))

    story_image(
        "review_clusters_full_tsne.png",
        "Notebook t-SNE map",
        "Use as a visual reference when highlighting clusters in the scatter plot.",
    )

with temporal_tab:
    section_header("Temporal Trends", "Monitor how sentiment and friction evolve over time.")
    if filtered_reviews_df.empty or "review_date" not in filtered_reviews_df.columns:
        st.info("Load the TSV dataset (with review dates) to explore temporal trends.")
    else:
        time_granularity = st.radio(
            "Group timeline by",
            ["Monthly", "Quarterly", "Yearly"],
            horizontal=True,
            key="temporal_time_granularity",
        )
        freq_map = {"Monthly": "ME", "Quarterly": "QE", "Yearly": "YE"}
        freq = freq_map[time_granularity]

        resampled = (
            filtered_reviews_df.set_index("review_date")
            .resample(freq)
            .agg(review_count=("review_id", "count"), avg_rating=("star_rating", "mean"))
            .reset_index()
        )

        if resampled.empty:
            st.info("Not enough data to generate a trend for the selected filters.")
        else:
            count_fig = px.line(
                resampled,
                x="review_date",
                y="review_count",
                markers=True,
                labels={"review_date": "Period", "review_count": "Review count"},
            )
            count_fig.update_layout(margin=dict(l=20, r=20, t=40, b=30))
            st.plotly_chart(count_fig, width="stretch")

            rating_fig = px.line(
                resampled,
                x="review_date",
                y="avg_rating",
                markers=True,
                labels={"review_date": "Period", "avg_rating": "Average rating"},
                range_y=[1, 5],
            )
            rating_fig.update_layout(margin=dict(l=20, r=20, t=40, b=30))
            st.plotly_chart(rating_fig, width="stretch")

    st.markdown("### Notebook trend exports")
    story_image(
        "pain_point_trends.png",
        "Pain point mentions over time",
        "Spot emerging issues that may require intervention.",
    )
    story_image(
        "positive_aspect_trends.png",
        "Positive aspects over time",
        "Identify strengths that are gaining traction.",
    )
    story_image(
        "sentiment_trend_multiline.png",
        "Sentiment trend by rating band",
        "Check whether low-star experiences are diverging from the baseline.",
    )

with comparison_tab:
    section_header("Comparative Analysis", "Stack top- and bottom-rated experiences side by side.")
    if comparison_markdown:
        with st.expander("Notebook comparative analysis", expanded=False):
            st.markdown(comparison_markdown)

    if filtered_clean_df.empty or "star_rating" not in filtered_clean_df.columns:
        st.info("Enable the cleaned insight records to compare cohorts.")
    else:
        cohort_df = filtered_clean_df.dropna(subset=["star_rating"]).copy()
        cohort_df["rating_bucket"] = cohort_df["star_rating"].apply(
            lambda value: "Top performers (‚≠ê 4-5)"
            if value >= 4
            else "Bottom performers (‚≠ê 1-2)"
            if value <= 2
            else "Middle tier"
        )

        top_reviews = cohort_df[cohort_df["rating_bucket"] == "Top performers (‚≠ê 4-5)"]
        bottom_reviews = cohort_df[cohort_df["rating_bucket"] == "Bottom performers (‚≠ê 1-2)"]

        if top_reviews.empty or bottom_reviews.empty:
            st.info(
                "Need both high-rating (4-5) and low-rating (1-2) reviews in view to run the comparison. "
                "Adjust rating filters or widen the date range."
            )
        else:
            st.markdown("### Positive Differentiators")
            pos_cols = st.columns(2)
            with pos_cols[0]:
                render_dynamic_terms("Top performer positives", top_reviews, pos_col, top_n)
            with pos_cols[1]:
                render_dynamic_terms("Bottom performer positives", bottom_reviews, pos_col, top_n)

            st.markdown("### Pain Point Contrast")
            pain_cols = st.columns(2)
            with pain_cols[0]:
                render_dynamic_terms("Top performer pain points", top_reviews, pain_col, top_n)
            with pain_cols[1]:
                render_dynamic_terms("Bottom performer pain points", bottom_reviews, pain_col, top_n)

            st.markdown("### Key Takeaways")
            st.markdown(
                "- **Double down on what works**: Highlight the differentiators that appear in the left column "
                "but are absent on the right.\n"
                "- **Remediate friction**: Pain points spiking in the bottom-right chart are prime candidates for product or CX fixes.\n"
                "- **Measure progress over time**: Re-run this comparison after interventions to see shifts in the distributions."
            )

# Footer ---------------------------------------------------------------------
st.markdown("---")
st.caption(
    "Built with Streamlit ‚Ä¢ Data sourced from Amazon customer reviews (Furniture category) ‚Ä¢ "
    "LLM-assisted annotations generated 2025-11-02"
)
